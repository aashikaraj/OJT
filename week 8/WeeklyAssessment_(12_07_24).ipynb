{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing a CNN for CIFAR-10 classification:\n",
        "\n",
        "## using PyTorch\n"
      ],
      "metadata": {
        "id": "0_q_JzdKone-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import libraries"
      ],
      "metadata": {
        "id": "kZjMM42Vo_Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "IfT8EamZo4Gi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Define the CNN architecture"
      ],
      "metadata": {
        "id": "UoXgyPlQpE8g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x5to1jFXoVkE"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Load and preprocess the CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "MVexpQ81pVZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xrGgwjVpU7w",
        "outputId": "3fba008c-3702-4e00-a0d3-73dbdd5cd028"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 103805271.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Initialize the model, loss function, and optimizer"
      ],
      "metadata": {
        "id": "fXCT-dsFphQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "C_v50m8ZphmB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "B3gLqaAspljn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_9fCeGopvAT",
        "outputId": "d9c762da-51d6-4003-a8d3-3be5094fdb58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.2915401914540459\n",
            "Epoch 2, Loss: 0.8905380308018316\n",
            "Epoch 3, Loss: 0.6985640084880698\n",
            "Epoch 4, Loss: 0.5328258204909847\n",
            "Epoch 5, Loss: 0.37390131182263575\n",
            "Epoch 6, Loss: 0.2392826494486893\n",
            "Epoch 7, Loss: 0.14687354332241026\n",
            "Epoch 8, Loss: 0.09450330904415806\n",
            "Epoch 9, Loss: 0.07736492001325311\n",
            "Epoch 10, Loss: 0.06645500760816057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ],
      "metadata": {
        "id": "PIBFl0uQpyEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test set: {100 * correct / total}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbszjYqQpyKr",
        "outputId": "d6c61166-d21d-43d3-e29f-786ac85ac94d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 72.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Potential improvements:\n",
        "\n",
        "1.   Use data augmentation techniques\n",
        "2.   Implement learning rate scheduling\n",
        "3.   Try different architectures (e.g., ResNet, VGG)\n",
        "4.   Use regularization techniques (e.g., dropout, weight decay)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LX-BQTW1v_Xf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Feedforward neural network for housing price prediction:\n",
        "\n",
        "## import the libraries"
      ],
      "metadata": {
        "id": "X7PDeyYfwXNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "KX89XKgFwcNz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess the data"
      ],
      "metadata": {
        "id": "OixAWSUqy7ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('housing_prices.csv')\n",
        "X = data.drop('Price', axis=1)\n",
        "y = data['Price']"
      ],
      "metadata": {
        "id": "MI943oaiy7tI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Encode categorical variables\n"
      ],
      "metadata": {
        "id": "ml7aMP55y79r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.get_dummies(X, columns=['Location'])"
      ],
      "metadata": {
        "id": "7atOqoHhy8In"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data"
      ],
      "metadata": {
        "id": "4WOnAlFTy8SP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Boko2rbly8bm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Normalize the input features"
      ],
      "metadata": {
        "id": "fIejYe53y8kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "NEhCdgQSy8si"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert to PyTorch tensors"
      ],
      "metadata": {
        "id": "z35GY2IGy82S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
        "y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
        "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
        "y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "PzToPbpFy8-a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the neural network"
      ],
      "metadata": {
        "id": "9ZqM2gS0y9IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HousingNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(HousingNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "w0qi7hsBy9Pg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the model, loss function, and optimizer"
      ],
      "metadata": {
        "id": "d7Yo4wO-y9Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train_scaled.shape[1]\n",
        "model = HousingNN(input_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "d6dUEm01y9gW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "6fkzcaXXy9oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(X_train_tensor), batch_size):\n",
        "        batch_X = X_train_tensor[i:i+batch_size]\n",
        "        batch_y = y_train_tensor[i:i+batch_size]\n",
        "\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WKkfeXBy9uz",
        "outputId": "7f121766-bf2d-464e-cbed-131667623667"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 138072817664.0000\n",
            "Epoch [200/1000], Loss: 137963257856.0000\n",
            "Epoch [300/1000], Loss: 137629859840.0000\n",
            "Epoch [400/1000], Loss: 136950161408.0000\n",
            "Epoch [500/1000], Loss: 135818543104.0000\n",
            "Epoch [600/1000], Loss: 134151208960.0000\n",
            "Epoch [700/1000], Loss: 131884064768.0000\n",
            "Epoch [800/1000], Loss: 128892387328.0000\n",
            "Epoch [900/1000], Loss: 125198508032.0000\n",
            "Epoch [1000/1000], Loss: 120816345088.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ],
      "metadata": {
        "id": "rpdj3qJQ0Fvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor)\n",
        "    mse = criterion(y_pred, y_test_tensor)\n",
        "    print(f'Mean Squared Error on test set: {mse.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOq6GN4i0GB0",
        "outputId": "862225a1-5b86-4e6a-fab6-360e6b3f71db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error on test set: 85973598208.0000\n"
          ]
        }
      ]
    }
  ]
}